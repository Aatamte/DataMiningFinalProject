# Evaluation settings - aligned with full.yaml training config

model:
  # API endpoint for the model being evaluated
  base_url: "https://api.openai.com/v1"
  name: "gpt-5"    # Model name at the endpoint

eval:
  subset: "train"  # "train", "test", or "all"
  n_questions: 20  # Total questions to evaluate (0 = all)
  n_samples: 1  # Number of runs per question
  start_from_question: 220  # Skip questions before this index (for resuming)

  # Must match training config for fair comparison
  max_turns: 2  # Aligned with full.yaml training.max_turns
  max_new_tokens: 4096  # Aligned with full.yaml training.max_new_tokens
  temperature: 0.7  # Single temperature for deterministic eval

judge:
  base_url: "http://10.0.0.9:1234/v1"  # Judge model endpoint
  model: "qwen/qwen3-vl-8b"

environment:
  sandbox_host: "localhost"
  sandbox_port: 8080

logging:
  output_dir: "train"
