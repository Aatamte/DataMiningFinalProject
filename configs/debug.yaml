# Minimal config for debugging/validation

model:
  name: "Qwen/Qwen3-4B-Instruct-2507"
  max_context: 2048

training:
  num_samples: 1
  num_epochs: 1
  num_rollouts: 2
  max_turns: 3
  learning_rate: 1.0e-5
  max_new_tokens: 512
  temperature: 0.7
  temperature_min: 0.7
  temperature_max: 1.15
  gamma: 0.99  # Discount factor for earlier turns
  correctness_weight: 0.75  # 75% correct answer, 25% approach quality
  lr_scheduler: "linear"  # "none" or "linear"
  lr_end: 0.0  # Final LR for linear decay
  rl_algo: "grpo"  # "reinforce" (fixed baseline) or "grpo" (group relative)
  shuffle: true  # Shuffle training samples each epoch

lora:
  enabled: true
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"

checkpoint:
  save_final: false
  save_every_epoch: false

judge:
  model: "deepseek/deepseek-r1-0528-qwen3-8b"
  base_url: "http://localhost:1234/v1"

environment:
  sandbox_host: "localhost"
  sandbox_port: 8080

logging:
  output_dir: "runs"
