# Default training configuration for SLM-RL Search

model:
  # Model to train (HuggingFace model ID)
  name: "Qwen/Qwen2.5-0.5B-Instruct"
  max_length: 2048

training:
  num_epochs: 3
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 1.0e-5
  warmup_steps: 100

  # GRPO specific
  num_generations: 4  # Number of rollouts per question
  temperature: 0.7

  # LoRA configuration (saves VRAM)
  use_lora: true
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  lora_target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"

environment:
  max_turns: 10
  judge_model: "qwen2.5:7b"
  judge_base_url: "http://localhost:11434/v1"
  embed_model: "all-MiniLM-L6-v2"
  embed_device: "cuda"
  chroma_db_dir: "data/.chroma_db"
  corpus_dataset: "willcb/rare-wiki-pages"
  corpus_split: "train"
  questions_dataset: "willcb/wiki-trivia-questions-v4"
  questions_split: "train"

evaluation:
  num_samples: 100
  temperature: 0.0  # Greedy for eval

logging:
  output_dir: "outputs"
  checkpoint_dir: "outputs/checkpoints"
  log_every_n_steps: 10
  save_every_n_steps: 100
