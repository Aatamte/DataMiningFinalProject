## Conclusions

This project demonstrates that a 4-billion parameter model can learn effective information-seeking behavior through reinforcement learning alone, without human demonstrations. By framing search as code generation rather than tool selection, the model learns to compose multi-step strategies—iterating through results, filtering with conditionals, and adapting based on intermediate outputs—achieving TODO% accuracy compared to TODO% for the untrained baseline. Our failure analysis reveals that most errors stem from behavioral issues (premature surrender, overly complex code) rather than capability limits, suggesting that continued training or curriculum learning could yield further gains. A natural next step is training the model to recognize retrieval failure and reformulate queries, rather than hallucinating answers when initial searches return irrelevant content.
